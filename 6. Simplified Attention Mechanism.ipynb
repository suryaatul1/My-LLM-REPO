{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d173d8-c96d-4df4-b700-97c59711911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42fc9a-1580-4fa4-9bcf-bfe6ae780b7c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Attention Mechanism</b> \n",
    "<p>    \n",
    "RNN where used for natural language processing.\n",
    "RNN was best for word to word transformation. However it posses a problem.\n",
    "\n",
    "When we have the context bigger then the long range dependencies is not able to be captured to make \n",
    "sense of overall context of sentence or paragraph.\n",
    "\n",
    "Hence there is a need for attention mechanism , to capture the long range dependencies in sentence or paragraph\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d940926-6788-4240-9b3e-4a09eb4f2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Your journey starts with one step\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10ba94-3fa1-43ec-b8c3-aeaa9cc9098a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Attention Mechanism</b> \n",
    "<p>    \n",
    "Lets take a look at the example sentence above = \"Your journey starts with one step\".\n",
    "After token embedding , we are able to project the tokens (words) in this sentence into higher dimension vector space.\n",
    "\n",
    "We can build and understand the semantics and meaning of the individual works .\n",
    "However the problem arise , we are still not able to build the relationship or context of particular word with the overall sentence /paragraph \n",
    "\n",
    "This is why we need attention mechanism , to build the relationship of each token with each other token . meaning how much attention has to paid to other tokens with respect the one in question\n",
    "Example :- if we take work journey , how is this journey work related to all the words in sentence , and need to understand how much of the weightage if to be assigned to each other word with journey in context.\n",
    "\n",
    "As part of attention mechanism we create a context vector for each of the tokens (toekn embedding)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a07d823-7dac-48a1-b195-554e41dd98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let consider below tensor is the vector embedding for the sentence \"Your journey starts with one step\"\n",
    "# The size is basically  (# of Tokens * Embedding size) \n",
    "# but for simplicity we are using much lower vector dimension\n",
    "\n",
    "inputs = torch.tensor(\n",
    " [[0.43, 0.15, 0.89],  # Your\n",
    " [0.55, 0.87, 0.66],  # journey\n",
    " [0.57, 0.85, 0.64],  # starts\n",
    " [0.22, 0.58, 0.33],  # with\n",
    " [0.77, 0.25, 0.10],  # one\n",
    " [0.05, 0.80, 0.55]] # step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057433f3-17a5-48a8-9e16-7e5c9c74f510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21860d67-38eb-458c-9cfb-e0be3059e2c1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Context vector</b> \n",
    "<p>    \n",
    "First Step to create the context Vector for each of the work in the sentence , is to calculate the intermediate attention score.\n",
    "\n",
    "The word selected for which the context Vector is to be generated is called \"QUERY\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f07b2f-986a-4457-a1af-56b1f10a77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create context vector initially for only one work \"journey\"\n",
    "# So  the \"journey\" is or QUERY\n",
    "\n",
    "\n",
    "query=inputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4074c2cd-9d8b-44d7-beef-990dc297b9c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Attention Score</b> \n",
    "<p>    \n",
    "Next step is to calculate the attention score using dot product the attention score calculation using dot product .\n",
    "It is a way to understand how closely the query is related to the other tokens .\n",
    "\n",
    "The dot product quantifies how much 2 vectors are aligned.\n",
    "\n",
    "If higher the dot product , the tokens are similar.\n",
    "Lower the doit product they are not related to similar to each other\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8053a1a6-e6b4-4537-912b-f06870cafd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create empty tensor of the shape equal to # of tokens\n",
    "# We want to calculate the attention score of \"journey\" token with respect to other tokens\n",
    "\n",
    "attention_score_token2 = torch.empty(inputs.shape[0])\n",
    "attention_score_token2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca988125-48b5-44a4-809a-a74e81971e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "# This attention score is only calculate for 2nd Token to find out\n",
    "# How this Token is related to other Tokens.\n",
    "\n",
    "for i , token_vector in enumerate(inputs):\n",
    "    attention_score_token2[i] = torch.dot(token_vector , query)\n",
    "\n",
    "print(attention_score_token2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721db10-fc41-43f9-875a-0fa513336527",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Normalization of Attention Score</b> \n",
    "<p>    \n",
    "This process of normalization means, the attention scores which have value greater then 1 has to be brought between 0 and 1\n",
    "\n",
    "This is required so that they can evaluated ith probabilities that LLM can very well generalize\n",
    "\n",
    "Meaning we should be able to tell give this % of attention to this tken etc.\n",
    "\n",
    "We use the torch softmax for this\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb86c2df-efcb-4df4-aaee-1e869d0f9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "weights = my_softmax(attention_score_token2)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b21ebe9b-8952-418d-8606-847adca5639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: tensor(1.)\n",
      "Attention Scores: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Probabilities in % : tensor([13.8548, 23.7891, 23.3274, 12.3992, 10.8182, 15.8114])\n"
     ]
    }
   ],
   "source": [
    "# Now we can tell the attention score in probabilities \n",
    "# if we sum then the value will be turned out to be = 1\n",
    "\n",
    "attention_score_token2_norm=torch.softmax(attention_score_token2, dim=0)\n",
    "print(\"Sum:\", attention_score_token2_norm.sum())\n",
    "print(\"Attention Scores:\" ,attention_score_token2_norm)\n",
    "print(\"Probabilities in % : {}\".format(attention_score_token2_norm *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89dcee-ec42-4ad5-943d-086a80c8844c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Calculate the Context Vector</b> \n",
    "<p>    \n",
    "Now we multiple Token embedding vectors with the corresponding attention weights and then summing the resultant Vectors  \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab3437a6-7b87-403e-8a9b-f3fa6cc932f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# This Content Vector is only for 2nd Token\n",
    "# This is enriched token embedding vector for 2nd Token\n",
    "# Each toekn have there contributions to this enrich this based on there attention score\n",
    "\n",
    "query = inputs[1]  # 2nd Token is the query = journey\n",
    "print(query.shape)\n",
    "context_vector_for_query = torch.zeros(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffafbd11-a8ce-4387-a23f-0a567dcc0584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "# this computation is only for 2nd Token \n",
    "\n",
    "for i , tokens_vector in enumerate(inputs):\n",
    "    context_vector_temp=attention_score_token2_norm[i]*tokens_vector\n",
    "    context_vector_for_query=context_vector_for_query+context_vector_temp\n",
    "\n",
    "print(context_vector_for_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f28c2-f766-49e3-8072-71284b641ff3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Context Vector for all tokens</b> \n",
    "<p>    \n",
    "We now generate the Context Vector for all the Tokens \n",
    "\n",
    "1. Create Attention Score for all tokens\n",
    "2. Normalize the attention score using softmax\n",
    "3. Multiple the Normalized attention score (weight) to scale down the Token Embedding\n",
    "4. Sum all the vectors to create context vector for all Tokens\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59d22430-f101-4948-a2a6-4e904bb8421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Attention score\n",
    "\n",
    "attn_scores_all_tokens = inputs @ inputs.T\n",
    "print(attn_scores_all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0143d94-96a3-4b53-aaf2-2223e9b55fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize using softmax\n",
    "\n",
    "attn_scores_all_tokens_norms= torch.softmax(attn_scores_all_tokens , dim=1)\n",
    "print(attn_scores_all_tokens_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "457e236d-2611-4a0f-a0a5-11852f6fd6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Context vector for all toekns using matrix multiplication\n",
    "# Dimensions are same as original token embedding vector\n",
    "\n",
    "context_vector_all_tokens= attn_scores_all_tokens_norms @ inputs\n",
    "\n",
    "print(context_vector_all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002c3b0-0923-49eb-a9a9-d8dd3e332462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
