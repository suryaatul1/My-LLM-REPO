{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e5c237-ec18-4523-ac44-601aeee84fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "from langchain_community.agent_toolkits.github.toolkit import GitHubToolkit\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from github import Github\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d27d03-1064-48e6-9635-f89ce93bdc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"openai/gpt-4.1\"\n",
    "token = os.environ[\"GH_OPENAI_TOKEN\"]\n",
    "\n",
    "github_repository = \"suryaatul1/genai-agentic-github-readme\"\n",
    "\n",
    "\n",
    "github1 = GitHubAPIWrapper()\n",
    "toolkit = GitHubToolkit.from_github_api_wrapper(github1)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "\n",
    "    print(tool.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb1921-f60b-4b72-bb8e-59b1bf0667dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureAIChatCompletionsModel(\n",
    "\n",
    "                endpoint=\"https://models.github.ai/inference\",\n",
    "                credential=os.environ['GH_OPENAI_TOKEN'],\n",
    "                #model=\"openai/gpt-4.1\",\n",
    "                #model=\"mistral-ai/Mistral-Large-2411\",\n",
    "                model=\"openai/gpt-4.1-mini\",\n",
    "                temperature=0,\n",
    "                top_p=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c711fc-4f1e-46cb-a5b0-f531345408c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def read_markdown_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads and returns the content of a markdown (.md) file from a GitHub repository.\n",
    "    \"\"\"\n",
    "    if not file_path.endswith('.md'):\n",
    "        return \"Only markdown (.md) files are supported.\"\n",
    "    try:\n",
    "        g = Github(os.environ[\"GH_OPENAI_TOKEN\"])\n",
    "        repo = g.get_repo(\"suryaatul1/genai-agentic-github-readme\")\n",
    "        file_content = repo.get_contents(file_path)\n",
    "        return file_content.decoded_content.decode()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71307b-7350-4e73-b9a8-8a9bce581b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system message with a variable\n",
    "system_template = \"You are a helpful assistant in searching and reading the markdown format files with .md extensions for given {topic}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# Define the human message with a variable\n",
    "human_template = \"Please help me find the .md file and its path in the github repository  for Topic :{topic} . it should be in the format of 'path/to/file.md'.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "human_template_read = \"The path returned should be used to read the .md file for the Topic :{topic} .\"\n",
    "human_message_prompt_read = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "human_template1 = \"Please help me summarize the content of the file and highlight key features for Topic :{topic} so a 5th grader can understand it.\"\n",
    "human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n",
    "\n",
    "# Combine them into a ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_prompt,\n",
    "    human_message_prompt,\n",
    "    human_message_prompt_read,\n",
    "    human_message_prompt1\n",
    "])\n",
    "\n",
    "\n",
    "prompt_arguments = {\n",
    "    \"topic\": \"Spring Boot . Extract the documentation from content.\"\n",
    "}\n",
    "\n",
    "# prompt_arguments = {\n",
    "#      \"topic\": \"what is spring boot used for.\"\n",
    "#  }\n",
    "\n",
    "# prompt_arguments = {\n",
    "#      \"topic\": \"list me all the markdowm files.\"\n",
    "#  }\n",
    "\n",
    "formatted_prompt = chat_prompt_template.format_prompt(**prompt_arguments)\n",
    "\n",
    "tools.append(read_markdown_file)\n",
    "\n",
    "# Initialize the agent\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Ask the agent to read a markdown file\n",
    "result = agent.invoke(formatted_prompt)\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
